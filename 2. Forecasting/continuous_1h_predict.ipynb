{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings                                  # `do not disturbe` mode\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np                               # vectors and matrices\n",
    "import pandas as pd                              # tables and data manipulations\n",
    "import matplotlib.pyplot as plt                  # plots\n",
    "                         # more plots\n",
    "\n",
    "from dateutil.relativedelta import relativedelta # working with dates with style\n",
    "from scipy.optimize import minimize              # for function minimization\n",
    "\n",
    "import statsmodels.formula.api as smf            # statistics and econometrics\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scs\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from itertools import product                    # some useful functions\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\n",
    "    style='whitegrid', \n",
    "    rc={'axes.facecolor': '.95', 'grid.color': '.95'}\n",
    ")\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, Flatten, GRU\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(2)\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('output.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find missing data!\n",
    "pd.date_range('2015-01-06 15:00:00', '2015-12-30 00:25:00', freq='5Min').difference(pd.to_datetime(df[\"time\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"time\"]= pd.to_datetime(df[\"time\"])\n",
    "df.set_index([\"time\"], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Toffice_reference', 'humidity', 'detected_motions', 'occupancy', 'office_CO2_concentratio','door'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['label']<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['label']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_5min = df\n",
    "data_per_Hour = df.resample('H').sum()\n",
    "data_per_5min.shape, data_per_Hour.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=50)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 15))\n",
    "sns.boxplot(data=df, y='label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(32,20))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(data_per_5min.loc['2015-02-01']['label'])\n",
    "#plt.plot(data_per_5min['occupancy'])\n",
    "#plt.plot(data_per_H.loc['2019-05-01':'2019-05-07',:])\n",
    "plt.title('per 5 min for random days')\n",
    "\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(data_per_Hour['2015-02-01']['label'])\n",
    "#plt.plot(data_per_D.loc['2019-05',:])\n",
    "plt.title('per hour for a random days')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20, 15))\n",
    "# ax1 = fig.add_subplot(211)\n",
    "# sns.boxplot(data=data, x='month', y='label', ax=ax1)\n",
    "# ax2 = fig.add_subplot(212)\n",
    "# sns.boxplot(data=data, x='weekday', y='label', ax=ax2)\n",
    "# # ax3 = fig.add_subplot(313)\n",
    "# # sns.boxplot(data=df, x='holiday', y='label', ax=ax3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_per_Hour[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "plot_acf(data['label'])\n",
    "plot_pacf(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add simple cal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "\n",
    "def add_time_features(df):\n",
    "    cet_index = df.index\n",
    "    df[\"month\"] = cet_index.month\n",
    "    df[\"weekday\"] = cet_index.weekday\n",
    "    df[\"hour\"] = cet_index.hour\n",
    "    #df[\"year\"] = cet_index.year\n",
    "    return df\n",
    "\n",
    "def add_holiday_features(df):\n",
    "    de_holidays = holidays.France()\n",
    "    cet_dates = pd.Series(df.index, index=df.index)\n",
    "    df[\"holiday\"] = cet_dates.apply(lambda d: d in de_holidays)\n",
    "    df[\"holiday\"] = df[\"holiday\"].astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_all_features(df, target_col=\"conso_global\"):\n",
    "    df = df.copy()\n",
    "    df = add_time_features(df)\n",
    "    #df = add_holiday_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_all_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icalendar import Calendar, Event\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evenement = []\n",
    "# debut = []\n",
    "# fin =[]\n",
    "\n",
    "\n",
    "# g = open('stephane_stephane.ploix@gmail.com.ics','rb')\n",
    "# gcal = Calendar.from_ical(g.read().decode())\n",
    "# for component in gcal.walk():\n",
    "#     if component.name == \"VEVENT\":\n",
    "\n",
    "#         evenement.append(str((component.get('summary'))))\n",
    "#         if len(str(component.get('dtstart').dt)) >12:\n",
    "#             debut.append(datetime.strptime(str(component.get('dtstart').dt)[:-6],'%Y-%m-%d %H:%M:%S'))\n",
    "#         else:\n",
    "#             debut.append(datetime.strptime(str(component.get('dtstart').dt), '%Y-%m-%d'))\n",
    "#         if component.get('dtend') is not None:\n",
    "#             fin.append(component.get('dtend').dt)\n",
    "#         else:\n",
    "#             fin.append(\"Nan\")\n",
    "\n",
    "# g.close()\n",
    "\n",
    "# calendrier = pd.DataFrame({'evenement': evenement,'debut':debut,'fin':fin})\n",
    "# calendrier['debut'] =pd.to_datetime(calendrier.debut)\n",
    "# calendrier.sort_values(['debut'], inplace=True)\n",
    "# calendrier = calendrier.set_index(calendrier['debut'])\n",
    "# calendrier = calendrier['2015-01-04':'2015-12-31']\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(20,9))\n",
    "# calendrier.evenement.value_counts()[0:100].plot.bar()\n",
    "# plt.show()\n",
    "\n",
    "# label = []\n",
    "# for k in calendrier.index:\n",
    "#     if \"point\" in calendrier['evenement'].loc[str(k)]:\n",
    "#         label.append(2)\n",
    "#     else:\n",
    "#         label.append(1)\n",
    "\n",
    "# calendrier['label']=label\n",
    "# print(calendrier.head())\n",
    "\n",
    "\n",
    "\n",
    "# cal = []\n",
    "# nom = []\n",
    "# for k in data['label']:\n",
    "#     cal.append(0)\n",
    "#     nom.append(\"None\")\n",
    "\n",
    "# data['calendrier'] = cal\n",
    "# data['nom']=nom\n",
    "\n",
    "# calendrier.drop_duplicates(subset =\"debut\",\n",
    "#                      keep = False, inplace = True)\n",
    "# print(calendrier[calendrier.index.duplicated()])\n",
    "# print(\"fin test\")\n",
    "\n",
    "# for k in calendrier.index:\n",
    "#     if k in data.index:\n",
    "#         data['calendrier'].loc[str(k)] = calendrier['label'].loc[str(k)]\n",
    "#         data['nom'].loc[str(k)] = calendrier['evenement'].loc[str(k)]\n",
    "\n",
    "# # plt.figure(figsize=(20,9))\n",
    "# # data['label'].plot()\n",
    "# # data['calendrier'].plot()\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(['nom'], axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20, 15))\n",
    "# ax1 = fig.add_subplot(211)\n",
    "# sns.boxplot(data=data, x='calendrier', y='label', ax=ax1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.arange(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# window 1h: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEADS\n",
    "leads = np.arange(1)\n",
    "\n",
    "hour_leads = [f\"hour_lead_{lead+1}\" for lead in leads ]\n",
    "weekday_leads = [f\"weekday_lead_{lead+1}\" for lead in leads ]\n",
    "month_leads = [f\"month_lead_{lead+1}\" for lead in leads ]\n",
    "# cal_leads = [f\"cal_lead_{lead+1}\" for lead in leads ]\n",
    "\n",
    "\n",
    "for lead, lead_H in zip(leads, hour_leads):\n",
    "    data[lead_H] = data[\"hour\"].shift(-(lead+1))\n",
    "    \n",
    "for lead, lead_W in zip(leads, weekday_leads):\n",
    "    data[lead_W] = data[\"weekday\"].shift(-(lead+1))\n",
    "    \n",
    "for lead, lead_M in zip(leads, month_leads):\n",
    "    data[lead_M] = data[\"month\"].shift(-(lead+1))\n",
    "    \n",
    "# for lead, lead_C in zip(leads, cal_leads):\n",
    "#     data[lead_C] = data[\"calendrier\"].shift(-(lead+1))    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LAGS\n",
    "lags = np.arange(1,25)\n",
    "lag_cols = [f\"label_lag_{lag}\" for lag in lags ]\n",
    "for lag, lag_col in zip(lags, lag_cols):\n",
    "    data[lag_col] = data[\"label\"].shift(lag)\n",
    "    \n",
    "hour_lags = [f\"hour_lag_{lag}\" for lag in lags ]\n",
    "weekday_lags = [f\"weekday_lag_{lag}\" for lag in lags ]\n",
    "month_lags = [f\"month_lag_{lag}\" for lag in lags ]\n",
    "# cal_lags = [f\"cal_lag_{lag}\" for lag in lags ]\n",
    "\n",
    "\n",
    "for lag, lag_H in zip(lags, hour_lags):\n",
    "    data[lag_H] = data[\"hour\"].shift(lag)\n",
    "    \n",
    "for lag, lag_W in zip(lags, weekday_lags):\n",
    "    data[lag_W] = data[\"weekday\"].shift(lag)\n",
    "    \n",
    "for lag, lag_M in zip(lags, month_lags):\n",
    "    data[lag_M] = data[\"month\"].shift(lag)\n",
    "\n",
    "# for lag, lag_C in zip(lags, cal_lags):\n",
    "#     data[lag_C] = data[\"calendrier\"].shift(lag)\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rolling \n",
    "\n",
    "wins = [3, 6, 12, 24, 36, 48]\n",
    "for win in wins:\n",
    "    for lag,lag_col in zip(lags, lag_cols):\n",
    "        data[f\"rmean_{lag}_{win}\"] = data[lag_col].transform(lambda x : x.rolling(win).mean())\n",
    "#         data[f\"rmax_{lag}_{win}\"] = data[\"label\"].shift(lag).transform(lambda x : x.rolling(win).max())\n",
    "#         data[f\"rmin_{lag}_{win}\"] = data[\"label\"].shift(lag).transform(lambda x : x.rolling(win).min())\n",
    "        data[f\"rstd_{lag}_{win}\"] = data[lag_col].transform(lambda x : x.rolling(win).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"label_lag_1\", \"label_lag_2\"], axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.rename(columns={\"label\": \"label_lead_0\"}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling\n",
    "scaler = MinMaxScaler()\n",
    "data['label_lead_0'] = scaler.fit_transform(pd.DataFrame(data['label_lead_0']))\n",
    "   \n",
    "\n",
    "lag_cols = [f\"label_lag_{lag}\" for lag in lags[2:] ]\n",
    "for lag_col in lag_cols:\n",
    "    data[lag_col] = scaler.transform(pd.DataFrame(data[lag_col]))\n",
    "\n",
    "    \n",
    "for win in wins:\n",
    "    for lag,lag_col in zip(lags, lag_cols):\n",
    "        data[f\"rmean_{lag}_{win}\"] = scaler.transform(pd.DataFrame(data[f\"rmean_{lag}_{win}\"]))\n",
    "#         data[f\"rmax_{lag}_{win}\"] = scaler.transform(pd.DataFrame(data[f\"rmax_{lag}_{win}\"]))\n",
    "#         data[f\"rmin_{lag}_{win}\"] = scaler.transform(pd.DataFrame(data[f\"rmin_{lag}_{win}\"]))\n",
    "        data[f\"rstd_{lag}_{win}\"] = scaler.transform(pd.DataFrame(data[f\"rstd_{lag}_{win}\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8506  *0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.iloc[0:6380]\n",
    "test_data = data.iloc[6380:]\n",
    "\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_cols = ['label_lead_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = train_data.drop(lead_cols, axis=1)\n",
    "y_train_data = train_data.loc[:, lead_cols]\n",
    "x_test_data = test_data.drop(lead_cols, axis=1)\n",
    "y_test_data = test_data.loc[:, lead_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -2\n",
    "features = []\n",
    "for col in y_train_data.columns:\n",
    "    correlation = pd.DataFrame(train_data.drop(lead_cols, axis=1).corrwith(train_data[col]), columns=['corr'])\n",
    "    thresh_corr = correlation[correlation['corr']> threshold]\n",
    "    features.append(list(thresh_corr.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"objective\":'regression',\n",
    "    \"is_unbalance\":True,\n",
    "    'learning_rate': 0.024398663784197132, 'max_depth': 5, 'num_leaves': 213, 'min_child_samples': 41\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "result = pd.DataFrame()\n",
    "models = dict()\n",
    "for counter, col in enumerate(tqdm(y_train_data.columns)):\n",
    "    \n",
    "    result[f'pred_{counter}'] = np.zeros(y_test_data.shape[0])\n",
    "    \n",
    "    used_features = features[counter]\n",
    "    \n",
    "    x_train_local = x_train_data.loc[:, used_features]\n",
    "    y_train_local = y_train_data.loc[:, col]\n",
    "    x_test_local = x_test_data.loc[:, used_features]\n",
    "    y_test_local = y_test_data.loc[:, col]\n",
    "    \n",
    "    \n",
    "    model = lgbm.LGBMRegressor(\n",
    "                    learning_rate= param[\"learning_rate\"],\n",
    "                    max_depth= param[\"max_depth\"],\n",
    "                    num_leaves= param[\"num_leaves\"],\n",
    "                    objective= param[\"objective\"],\n",
    "                    is_unbalance=param[\"is_unbalance\"],\n",
    "                    min_child_samples=param['min_child_samples']\n",
    "\n",
    "    )\n",
    "\n",
    "    n_splits = 6\n",
    "    cv = model_selection.KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    val_scores = [0] * n_splits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #feature_importances = pd.DataFrame(index=x_train_local.columns)\n",
    "\n",
    "    for i, (fit_idx, val_idx) in enumerate(cv.split(x_train_local, y_train_local)):\n",
    "\n",
    "        X_fit = x_train_local.iloc[fit_idx]\n",
    "        y_fit = y_train_local.iloc[fit_idx]\n",
    "        X_val = x_train_local.iloc[val_idx]\n",
    "        y_val = y_train_local.iloc[val_idx]\n",
    "\n",
    "        model.fit(\n",
    "            X_fit,\n",
    "            y_fit,\n",
    "            eval_set=[(X_fit, y_fit), (X_val, y_val)],\n",
    "            eval_names=('fit', 'val'),\n",
    "            eval_metric='l2',\n",
    "            early_stopping_rounds=200,\n",
    "            feature_name=X_fit.columns.tolist(),\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        val_scores[i] = np.sqrt(model.best_score_['val']['l2'])\n",
    "        result[f'pred_{counter}'] += model.predict(x_test_local, num_iteration=model.best_iteration_)\n",
    "        #feature_importances[i] = model.feature_importances_\n",
    "\n",
    "        print('Fold {} RMSLE: {:.5f}'.format(i+1, val_scores[i]))\n",
    "\n",
    "    result[f'pred_{counter}'] /= n_splits\n",
    "    result[f'pred_{counter}'] = np.expm1(result[f'pred_{counter}'])\n",
    "\n",
    "    val_mean = np.mean(val_scores)\n",
    "    val_std = np.std(val_scores)\n",
    "\n",
    "    print('Local RMSLE: {:.5f} (±{:.5f})'.format(val_mean, val_std))\n",
    "    models[col] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = y_test_data.values.flatten()\n",
    "final_resut = result.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "plt.plot(final_test[330:500], marker='.',label='Target')\n",
    "plt.plot(final_resut[330:500], marker='.', label='Predictions')\n",
    "plt.title('Elec consumption')\n",
    "plt.xlabel('Time(h)')\n",
    "plt.ylabel('Elec consump (khw)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"The RMSE for Stacked LSTM model is: %f\" %np.sqrt(mean_squared_error(final_test,final_resut)))\n",
    "print( \"The accuracy of Stacked LSTM model is: %f\" %r2_score(final_test,final_resut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
