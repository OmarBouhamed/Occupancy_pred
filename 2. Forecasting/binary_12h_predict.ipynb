{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings                                  # `do not disturbe` mode\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np                               # vectors and matrices\n",
    "import pandas as pd                              # tables and data manipulations\n",
    "import matplotlib.pyplot as plt                  # plots\n",
    "                         # more plots\n",
    "\n",
    "from dateutil.relativedelta import relativedelta # working with dates with style\n",
    "from scipy.optimize import minimize              # for function minimization\n",
    "\n",
    "import statsmodels.formula.api as smf            # statistics and econometrics\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scs\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from itertools import product                    # some useful functions\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\n",
    "    style='whitegrid', \n",
    "    rc={'axes.facecolor': '.95', 'grid.color': '.95'}\n",
    ")\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, Flatten, GRU\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(2)\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ob-occupancy.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find missing data!\n",
    "pd.date_range('2015-01-06 15:00:00', '2015-12-30 00:25:00', freq='5Min').difference(pd.to_datetime(df[\"time\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"time\"]= pd.to_datetime(df[\"time\"])\n",
    "df.set_index([\"time\"], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Toffice_reference', 'humidity', 'detected_motions', 'power', 'office_CO2_concentration','door'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(df, x=\"label\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "ax = sns.histplot(df)\n",
    "ax.set_xlabel('occurance')\n",
    "ax.set_title('occurence per hour')\n",
    "ax.figure.savefig(\"images/m_data_perh.eps\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7417/df.label.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data.label > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(data, x=\"label\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "plot_acf(data['label'])\n",
    "plot_pacf(data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add simple cal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "\n",
    "def add_time_features(df):\n",
    "    cet_index = df.index\n",
    "    df[\"month\"] = cet_index.month\n",
    "    df[\"weekday\"] = cet_index.weekday\n",
    "    df[\"hour\"] = cet_index.hour\n",
    "    #df[\"year\"] = cet_index.year\n",
    "    return df\n",
    "\n",
    "def add_holiday_features(df):\n",
    "    de_holidays = holidays.France()\n",
    "    cet_dates = pd.Series(df.index, index=df.index)\n",
    "    df[\"holiday\"] = cet_dates.apply(lambda d: d in de_holidays)\n",
    "    df[\"holiday\"] = df[\"holiday\"].astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_all_features(df, target_col=\"conso_global\"):\n",
    "    df = df.copy()\n",
    "    df = add_time_features(df)\n",
    "    #df = add_holiday_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_all_features(data)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the calenda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icalendar import Calendar, Event\n",
    "from datetime import datetime\n",
    "\n",
    "evenement = []\n",
    "debut = []\n",
    "fin =[]\n",
    "\n",
    "\n",
    "g = open('stephane_stephane.ploix@gmail.com.ics','rb')\n",
    "gcal = Calendar.from_ical(g.read().decode())\n",
    "for component in gcal.walk():\n",
    "    if component.name == \"VEVENT\":\n",
    "\n",
    "        evenement.append(str((component.get('summary'))))\n",
    "        if len(str(component.get('dtstart').dt)) >12:\n",
    "            debut.append(datetime.strptime(str(component.get('dtstart').dt)[:-6],'%Y-%m-%d %H:%M:%S'))\n",
    "        else:\n",
    "            debut.append(datetime.strptime(str(component.get('dtstart').dt), '%Y-%m-%d'))\n",
    "        if component.get('dtend') is not None:\n",
    "            fin.append(component.get('dtend').dt)\n",
    "        else:\n",
    "            fin.append(\"Nan\")\n",
    "\n",
    "g.close()\n",
    "\n",
    "calendrier = pd.DataFrame({'evenement': evenement,'debut':debut,'fin':fin})\n",
    "calendrier['debut'] =pd.to_datetime(calendrier.debut)\n",
    "calendrier.sort_values(['debut'], inplace=True)\n",
    "calendrier = calendrier.set_index(calendrier['debut'])\n",
    "calendrier = calendrier['2015-01-04':'2015-12-31']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,9))\n",
    "calendrier.evenement.value_counts()[0:100].plot.bar()\n",
    "plt.show()\n",
    "\n",
    "label = []\n",
    "for k in calendrier.index:\n",
    "    if \"point\" in calendrier['evenement'].loc[str(k)]:\n",
    "        label.append(2)\n",
    "    else:\n",
    "        label.append(1)\n",
    "\n",
    "calendrier['label']=label\n",
    "print(calendrier.head())\n",
    "\n",
    "\n",
    "\n",
    "cal = []\n",
    "nom = []\n",
    "for k in data['label']:\n",
    "    cal.append(0)\n",
    "    nom.append(\"None\")\n",
    "\n",
    "data['calendrier'] = cal\n",
    "data['nom']=nom\n",
    "\n",
    "calendrier.drop_duplicates(subset =\"debut\",\n",
    "                     keep = False, inplace = True)\n",
    "print(calendrier[calendrier.index.duplicated()])\n",
    "print(\"fin test\")\n",
    "\n",
    "for k in calendrier.index:\n",
    "    if k in data.index:\n",
    "        data['calendrier'].loc[str(k)] = calendrier['label'].loc[str(k)]\n",
    "        data['nom'].loc[str(k)] = calendrier['evenement'].loc[str(k)]\n",
    "\n",
    "# plt.figure(figsize=(20,9))\n",
    "# data['label'].plot()\n",
    "# data['calendrier'].plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['nom'], axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 15))\n",
    "ax1 = fig.add_subplot(211)\n",
    "sns.boxplot(data=data, x='calendrier', y='label', ax=ax1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# window 12h: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEADS\n",
    "leads = np.arange(11)\n",
    "lead_cols = [f\"label_lead_{lead+1}\" for lead in leads ]\n",
    "for lead, lead_col in zip(leads, lead_cols):\n",
    "    data[lead_col] = data[\"label\"].shift(-(lead+1))\n",
    "\n",
    "hour_leads = [f\"hour_lead_{lead+1}\" for lead in leads ]\n",
    "weekday_leads = [f\"weekday_lead_{lead+1}\" for lead in leads ]\n",
    "month_leads = [f\"month_lead_{lead+1}\" for lead in leads ]\n",
    "cal_leads = [f\"cal_lead_{lead+1}\" for lead in leads ]\n",
    "\n",
    "\n",
    "for lead, lead_H in zip(leads, hour_leads):\n",
    "    data[lead_H] = data[\"hour\"].shift(-(lead+1))\n",
    "    \n",
    "for lead, lead_W in zip(leads, weekday_leads):\n",
    "    data[lead_W] = data[\"weekday\"].shift(-(lead+1))\n",
    "    \n",
    "for lead, lead_M in zip(leads, month_leads):\n",
    "    data[lead_M] = data[\"month\"].shift(-(lead+1))\n",
    "    \n",
    "for lead, lead_C in zip(leads, cal_leads):\n",
    "    data[lead_C] = data[\"calendrier\"].shift(-(lead+1))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lags\n",
    "lags = np.arange(1,25)\n",
    "lag_cols = [f\"label_lag_{lag}\" for lag in lags ]\n",
    "for lag, lag_col in zip(lags, lag_cols):\n",
    "    data[lag_col] = data[\"label\"].shift(lag)\n",
    "\n",
    "hour_lags = [f\"hour_lag_{lag}\" for lag in lags ]\n",
    "weekday_lags = [f\"weekday_lag_{lag}\" for lag in lags ]\n",
    "month_lags = [f\"month_lag_{lag}\" for lag in lags ]\n",
    "cal_lags = [f\"cal_lag_{lag}\" for lag in lags ]\n",
    "\n",
    "\n",
    "for lag, lag_H in zip(lags, hour_lags):\n",
    "    data[lag_H] = data[\"hour\"].shift(lag)\n",
    "    \n",
    "for lag, lag_W in zip(lags, weekday_lags):\n",
    "    data[lag_W] = data[\"weekday\"].shift(lag)\n",
    "    \n",
    "for lag, lag_M in zip(lags, month_lags):\n",
    "    data[lag_M] = data[\"month\"].shift(lag)\n",
    "\n",
    "for lag, lag_C in zip(lags, cal_lags):\n",
    "    data[lag_C] = data[\"calendrier\"].shift(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rolling \n",
    "\n",
    "wins = [12, 24, 36, 48, 60, 72]\n",
    "for win in wins:\n",
    "    for lag,lag_col in zip(lags, lag_cols):\n",
    "        data[f\"rmean_{lag}_{win}\"] = data[lag_col].transform(lambda x : x.rolling(win).mean())\n",
    "#         data[f\"rmax_{lag}_{win}\"] = data[\"label\"].shift(lag).transform(lambda x : x.rolling(win).max())\n",
    "#         data[f\"rmin_{lag}_{win}\"] = data[\"label\"].shift(lag).transform(lambda x : x.rolling(win).min())\n",
    "        data[f\"rstd_{lag}_{win}\"] = data[lag_col].transform(lambda x : x.rolling(win).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.rename(columns={\"label\": \"label_lead_0\"}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 24 step window no overlap\n",
    "data = data.iloc[[i for i in range(0,len(data),12)]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(643+103)*0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = data.iloc[0:103].append(data.iloc[206:]) \n",
    "# test_data = data.iloc[103:206]\n",
    "train_data = data.iloc[103:]\n",
    "test_data = data.iloc[0:103]\n",
    "\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_cols.insert(0, \"label_lead_0\") \n",
    "lead_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = train_data.drop(lead_cols, axis=1)\n",
    "y_train_data = train_data.loc[:, lead_cols]\n",
    "x_test_data = test_data.drop(lead_cols, axis=1)\n",
    "y_test_data = test_data.loc[:, lead_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -2\n",
    "features = []\n",
    "for col in y_train_data.columns[0:1]:\n",
    "    correlation = pd.DataFrame(train_data.drop(lead_cols, axis=1).corrwith(train_data[col]), columns=['corr'])\n",
    "    thresh_corr = correlation[abs(correlation['corr'])> threshold]\n",
    "    features.append(list(thresh_corr.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = x_train_data.astype(int)\n",
    "y_train_data = y_train_data.astype(int)\n",
    "x_test_data = x_test_data.astype(int)\n",
    "y_test_data = y_test_data.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateBalancedSampleWeights(y_train, largest_class_weight_coef):\n",
    "    classes = np.unique(y_train, axis = 0)\n",
    "    classes.sort()\n",
    "    class_samples = np.bincount(y_train)\n",
    "    total_samples = class_samples.sum()\n",
    "    n_classes = len(class_samples)\n",
    "    weights = total_samples / (n_classes * class_samples * 1.0)\n",
    "    class_weight_dict = {key : value for (key, value) in zip(classes, weights)}\n",
    "    class_weight_dict[classes[1]] = class_weight_dict[classes[1]] * largest_class_weight_coef\n",
    "    sample_weights = [class_weight_dict[y] for y in y_train]\n",
    "    return sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"objective\":'regression',\n",
    "    \"is_unbalance\":True,\n",
    "    'learning_rate': 0.2458048231236954,\n",
    "     'max_depth': 26,\n",
    "     'num_leaves': 70,\n",
    "     'min_child_samples': 47\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "result = pd.DataFrame()\n",
    "models = dict()\n",
    "for counter, col in enumerate(tqdm(y_train_data.columns)):\n",
    "    \n",
    "    result[f'pred_{counter}'] = np.zeros(y_test_data.shape[0])\n",
    "    \n",
    "    used_features = features[0]\n",
    "    \n",
    "    x_train_local = x_train_data.loc[:, used_features]\n",
    "    y_train_local = y_train_data.loc[:, col]\n",
    "    x_test_local = x_test_data.loc[:, used_features]\n",
    "    y_test_local = y_test_data.loc[:, col]\n",
    "    \n",
    "    model = lgbm.LGBMRegressor(\n",
    "                    learning_rate= param[\"learning_rate\"],\n",
    "                    max_depth= param[\"max_depth\"],\n",
    "                    num_leaves= param[\"num_leaves\"],\n",
    "                    objective= param[\"objective\"],\n",
    "                    is_unbalance=param[\"is_unbalance\"],\n",
    "                    min_child_samples=param['min_child_samples']\n",
    "    )\n",
    "\n",
    "    n_splits = 6\n",
    "    cv = model_selection.KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    val_scores = [0] * n_splits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #feature_importances = pd.DataFrame(index=x_train_local.columns)\n",
    "\n",
    "    for i, (fit_idx, val_idx) in enumerate(cv.split(x_train_local, y_train_local)):\n",
    "\n",
    "        X_fit = x_train_local.iloc[fit_idx]\n",
    "        y_fit = y_train_local.iloc[fit_idx]\n",
    "        X_val = x_train_local.iloc[val_idx]\n",
    "        y_val = y_train_local.iloc[val_idx]\n",
    "\n",
    "        model.fit(\n",
    "            X_fit,\n",
    "            y_fit,\n",
    "            eval_set=[(X_fit, y_fit), (X_val, y_val)],\n",
    "            eval_names=('fit', 'val'),\n",
    "            eval_metric='l2',\n",
    "            early_stopping_rounds=200,\n",
    "            feature_name=X_fit.columns.tolist(),\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        val_scores[i] = np.sqrt(model.best_score_['val']['l2'])\n",
    "        result[f'pred_{counter}'] += model.predict(x_test_local, num_iteration=model.best_iteration_)\n",
    "        #feature_importances[i] = model.feature_importances_\n",
    "\n",
    "        print('Fold {} RMSLE: {:.5f}'.format(i+1, val_scores[i]))\n",
    "\n",
    "    result[f'pred_{counter}'] /= n_splits\n",
    "    result[f'pred_{counter}'] = np.expm1(result[f'pred_{counter}'])\n",
    "\n",
    "    val_mean = np.mean(val_scores)\n",
    "    val_std = np.std(val_scores)\n",
    "\n",
    "    print('Local RMSLE: {:.5f} (±{:.5f})'.format(val_mean, val_std))\n",
    "    models[col] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level(x):\n",
    "    res= 0\n",
    "    if x < 0.5 :\n",
    "        res = 0\n",
    "    if 0.5 <= x : \n",
    "        res =1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = y_test_data.values.flatten()\n",
    "final_resut = result.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_resut = [ level(x) for x in final_resut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_resut2 = np.array(final_resut).reshape(103,12)\n",
    "final_test2 = np.array(final_test).reshape(103,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = np.arange(24)\n",
    "pred_cols = [f\"label_pred_{lead+1}\" for lead in leads ]\n",
    "pred_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(final_test, final_resut, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
