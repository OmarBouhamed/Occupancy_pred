{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings                                  # `do not disturbe` mode\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np                               # vectors and matrices\n",
    "import pandas as pd                              # tables and data manipulations\n",
    "import matplotlib.pyplot as plt                  # plots\n",
    "                         # more plots\n",
    "\n",
    "from dateutil.relativedelta import relativedelta # working with dates with style\n",
    "from scipy.optimize import minimize              # for function minimization\n",
    "\n",
    "import statsmodels.formula.api as smf            # statistics and econometrics\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scs\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from itertools import product                    # some useful functions\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\n",
    "    style='whitegrid', \n",
    "    rc={'axes.facecolor': '.95', 'grid.color': '.95'}\n",
    ")\n",
    "# sns.set_palette(palette='deep')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(2)\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('values_office.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_data = df[df.label == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[df.label != -1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(train_data, x=\"label\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.time = pd.to_datetime(train_data.time)\n",
    "estimation_data.time = pd.to_datetime(estimation_data.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.set_index('time', inplace=True)\n",
    "estimation_data.set_index('time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.resample('H').mean()\n",
    "estimation_data = estimation_data.resample('H').mean().pad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(train_data, x=\"label\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level(x):\n",
    "    res= 0\n",
    "    if x < 0.5 :\n",
    "        res = 0\n",
    "    if 0.5 <= x:\n",
    "        res =1\n",
    "    if 1.5 <= x :\n",
    "        res =2 \n",
    "#     if 2.5 <= x:\n",
    "#         res =3\n",
    "#     if 3.5 <= x:\n",
    "# #         res =4\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.columns = ['Toffice_reference', 'humidity', 'detected_motions', 'power',\n",
    "#        'office_CO2_concentration', 'door', 'occup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['occup'] = train_data.label.apply(lambda x : 0 if x <= 0.5 else 1)\n",
    "train_data['occup'] = train_data.label.apply(lambda x : level(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(train_data, x=\"occup\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.occup.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.drop(['label'], axis =1, inplace=True)\n",
    "# estimation_data.drop(['label'], axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate features and target\n",
    "target = \"occup\"\n",
    "X = train_data.drop(target, axis =1)\n",
    "Y = train_data.loc[:,target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=X, orient=\"v\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #normalize data\n",
    "# X = (X - X.mean())/X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=X, orient=\"v\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairplot\n",
    "merged = X[:]\n",
    "merged[target] = Y\n",
    "sns.pairplot(merged, hue = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairplot\n",
    "merged = X[:][['power', 'detected_motions']]\n",
    "merged[target] = Y\n",
    "sns.pairplot(merged, hue = target)\n",
    "plt.savefig('img/parplot-m.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into 80% training set and 20% testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build and train the model\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the unseen test set and draw the confusion matrix\n",
    "y_predict = svc_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy score: %.2f%%' %(accuracy_score(y_test, y_predict)*100))  \n",
    "#print('Precision score: %.2f%%' % (precision_score(y_test, y_predict)*100))\n",
    "#print('Recall score: %.2f%%' % (recall_score(y_test, y_predict)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='g').set(title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot the confusion matrix and the roc curve\n",
    "# fig, [ax1, ax2] = plt.subplots(1,2)\n",
    "# fpr, tpr, _ = roc_curve(y_test,y_predict)\n",
    "# ax1.plot(fpr, tpr, lw = 2, label = 'AUC: {:.2f}'.format(auc(fpr, tpr)))\n",
    "# ax1.plot([0, 1], [0, 1],\n",
    "#             linestyle = '--',\n",
    "#             color = (0.6, 0.6, 0.6),\n",
    "#             label = 'Random guessing')\n",
    "# ax1.plot([0, 0, 1], [0, 1, 1],\n",
    "#             linestyle = ':',\n",
    "#             color = 'black', \n",
    "#             label = 'Perfect performance')\n",
    "# ax1.set_xlim([-0.05, 1.05])\n",
    "# ax1.set_ylim([-0.05, 1.05])\n",
    "# ax1.set_xlabel('False Positive Rate (FPR)')\n",
    "# ax1.set_ylabel('True Positive Rate (TPR)')\n",
    "# ax1.set_title('Receiver Operator Characteristic (ROC) Curve')\n",
    "# ax1.legend(loc = \"lower right\")\n",
    "# fig.tight_layout() \n",
    "# sns.heatmap(cm, annot=True, fmt='g', ax=ax2).set(title='Confusion matrix')\n",
    "# # -----------------------------------------------------\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Improoving the model\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#improoving the model using grid search to find the best parameters\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predixt the classes of the test set\n",
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, grid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy score: %.2f%%' %(accuracy_score(y_test, grid_predictions)*100))  \n",
    "# print('Precision score: %.2f%%' % (precision_score(y_test, grid_predictions)*100))\n",
    "# print('Recall score: %.2f%%' % (recall_score(y_test, grid_predictions)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='g').set(title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, grid_predictions, digits=4 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Known classification models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "def run_classifier(clf, param_grid, title, X_train, X_test):\n",
    "    # -----------------------------------------------------\n",
    "    cv = StratifiedKFold(n_splits= 3, shuffle = True, random_state= 123)\n",
    "    # Randomized grid search\n",
    "    n_iter_search = 10\n",
    "    gs = RandomizedSearchCV(clf, \n",
    "                            param_distributions = param_grid,\n",
    "                            n_iter = n_iter_search, \n",
    "                            cv = cv, \n",
    "                            iid = False,\n",
    "                            scoring= 'accuracy',\n",
    "                            verbose=1,\n",
    "                            n_jobs=-1)\n",
    "    # -----------------------------------------------------\n",
    "    # Train model\n",
    "    gs.fit(X_train, y_train)  \n",
    "    print(\"The best parameters are %s\" % (gs.best_params_)) \n",
    "    # Predict on test set\n",
    "    y_pred = gs.best_estimator_.predict(X_test)\n",
    "    # Get Probability estimates\n",
    "    y_prob = gs.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "    # -----------------------------------------------------\n",
    "#     print('Accuracy score: %.2f%%' %(accuracy_score(y_test, y_pred)*100))  \n",
    "#     print('Precision score: %.2f%%' % (precision_score(y_test, y_pred)*100))\n",
    "#     print('Recall score: %.2f%%' % (recall_score(y_test, y_pred)*100))\n",
    "#     MSE=mean_squared_error(y_test, y_pred)\n",
    "#     print(\"MSE\", MSE)\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    # ----------------------------------------------------- \n",
    "    fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(21, 7))\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot = True, cbar = False, fmt = \"d\", linewidths = .5, cmap = \"Blues\", ax = ax1)\n",
    "    ax1.set_title(\"Confusion Matrix\")\n",
    "    ax1.set_xlabel(\"Predicted class\")\n",
    "    ax1.set_ylabel(\"Actual class\")\n",
    "    fig.tight_layout()\n",
    "    # -----------------------------------------------------\n",
    "    # Plot ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    ax2.plot(fpr, tpr, lw = 2, label = 'AUC: {:.2f}'.format(auc(fpr, tpr)))\n",
    "    ax2.plot([0, 1], [0, 1],\n",
    "             linestyle = '--',\n",
    "             color = (0.6, 0.6, 0.6),\n",
    "             label = 'Random guessing')\n",
    "    ax2.plot([0, 0, 1], [0, 1, 1],\n",
    "             linestyle = ':',\n",
    "             color = 'black', \n",
    "             label = 'Perfect performance')\n",
    "    ax2.set_xlim([-0.05, 1.05])\n",
    "    ax2.set_ylim([-0.05, 1.05])\n",
    "    ax2.set_xlabel('False Positive Rate (FPR)')\n",
    "    ax2.set_ylabel('True Positive Rate (TPR)')\n",
    "    ax2.set_title('Receiver Operator Characteristic (ROC) Curve')\n",
    "    ax2.legend(loc = \"lower right\")\n",
    "    fig.tight_layout()      \n",
    "    # -----------------------------------------------------\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "param_grid = {'penalty': ['l2'],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_classifier(lr, param_grid, 'Logistic Regression', X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "param_grid = {'criterion': ['gini', 'entropy'],\n",
    "              'splitter': ['best', 'random'],\n",
    "              'max_depth': np.arange(1, 20, 2),\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2, 4, 10],\n",
    "              'max_features': ['auto', 'sqrt', 'log2', None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_classifier(dtree, param_grid, \"Decision Tree\", X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "param_grid = {'n_estimators': [100, 200],\n",
    "              'max_depth': [10, 20, 100, None],\n",
    "              'max_features': ['auto', 'sqrt', None],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2, 4, 10],\n",
    "              'bootstrap': [True, False],\n",
    "              'criterion': ['gini', 'entropy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_classifier(rf, param_grid, 'Random Forest', X_train, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "param_grid = {'n_estimators': [100, 200],\n",
    "              'max_depth': [10, 20, 100, None],\n",
    "              'max_features': ['auto', 'sqrt', None],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2, 4, 10],\n",
    "              'bootstrap': [True, False],\n",
    "              'criterion': ['gini', 'entropy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "def run_classifier_2(clf, param_grid, title, X_train, X_test):\n",
    "    # -----------------------------------------------------\n",
    "    cv = StratifiedKFold(n_splits= 3, shuffle = True, random_state= 123)\n",
    "    # Randomized grid search\n",
    "    n_iter_search = 10\n",
    "    gs = RandomizedSearchCV(clf, \n",
    "                            param_distributions = param_grid,\n",
    "                            n_iter = n_iter_search, \n",
    "                            cv = cv, \n",
    "                            iid = False,\n",
    "                            scoring= 'accuracy',\n",
    "                            verbose=1,\n",
    "                            n_jobs=-1)\n",
    "    # -----------------------------------------------------\n",
    "    # Train model\n",
    "    gs.fit(X_train, y_train)  \n",
    "    print(\"The best parameters are %s\" % (gs.best_params_)) \n",
    "    # Predict on test set\n",
    "    y_pred = gs.best_estimator_.predict(X_test)\n",
    "    # Get Probability estimates\n",
    "    y_prob = gs.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "    # -----------------------------------------------------\n",
    "    print('Accuracy score: %.2f%%' %(accuracy_score(y_test, y_pred)*100))  \n",
    "#     print('Precision score: %.2f%%' % (precision_score(y_test, y_pred)*100))\n",
    "#     print('Recall score: %.2f%%' % (recall_score(y_test, y_pred)*100))\n",
    "    # ----------------------------------------------------- \n",
    "    fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(21, 7))\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot = True, cbar = False, fmt = \"d\", linewidths = .5, cmap = \"Blues\", ax = ax1)\n",
    "    ax1.set_title(\"Confusion Matrix\")\n",
    "    ax1.set_xlabel(\"Predicted class\")\n",
    "    ax1.set_ylabel(\"Actual class\")\n",
    "    fig.tight_layout()\n",
    "    # -----------------------------------------------------\n",
    "#     # Plot ROC curve\n",
    "#     fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "#     ax2.plot(fpr, tpr, lw = 2, label = 'AUC: {:.2f}'.format(auc(fpr, tpr)))\n",
    "#     ax2.plot([0, 1], [0, 1],\n",
    "#              linestyle = '--',\n",
    "#              color = (0.6, 0.6, 0.6),\n",
    "#              label = 'Random guessing')\n",
    "#     ax2.plot([0, 0, 1], [0, 1, 1],\n",
    "#              linestyle = ':',\n",
    "#              color = 'black', \n",
    "#              label = 'Perfect performance')\n",
    "#     ax2.set_xlim([-0.05, 1.05])\n",
    "#     ax2.set_ylim([-0.05, 1.05])\n",
    "#     ax2.set_xlabel('False Positive Rate (FPR)')\n",
    "#     ax2.set_ylabel('True Positive Rate (TPR)')\n",
    "#     ax2.set_title('Receiver Operator Characteristic (ROC) Curve')\n",
    "#     ax2.legend(loc = \"lower right\")\n",
    "    fig.tight_layout()      \n",
    "    # -----------------------------------------------------\n",
    "    plt.show()\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = run_classifier_2(rf, param_grid, 'Random Forest', X_train, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = rf.best_estimator_.predict(estimation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.scatterplot(x=y_test, y=pred)\n",
    "plt.xlabel('Real Occupancy')\n",
    "plt.ylabel('Estimated Occupancy')\n",
    "# plt.savefig('img/estimationn.eps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(final_test, predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_data['occup'] = predict\n",
    "# estimation_data['time'] = estim_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_data.occup.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [train_data, estimation_data]\n",
    "\n",
    "final_df =  pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.occup.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(final_df, x=\"occup\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.to_csv('ob-occupancy-bin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
